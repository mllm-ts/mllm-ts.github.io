<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Multimodal LLMs Advance Time Series Analysis">
  <meta name="keywords" content="Multimodal LLMs, Time Series Analysis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Multimodal LLMs Advance Time Series Analysis</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>


<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-3 publication-title">An initiative to advance time series analysis in the era of multimodal LLMs</h1>
            <h1 class="title is-5 publication-title">(Contact: <a href="https://xiongxiaoxu.github.io/" target="_blank">Xiongxiao Xu, 
                            <a href="https://www.cs.emory.edu/~kshu5/" target="_blank">Kai Shu</a>)
            </h1>
            <ul>
              <div class="column is-one-third">
              <h2 class="title is-5">Table of Contents</h2>
              </div>

              <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <div class="content has-text-justified">
                    <a href="#tsad">- Can Multimodal LLMs Perform Time Series Anomaly Detection? </a>
                </div>

                <div class="content has-text-justified">
                     <a href="#survey">- Beyond Numbers: A Survey of Time Series Analysis in the Era of Multimodal LLMs </a>
                </div>
              </div>
              </div>

            </ul>
          </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" id="tsad">Can Multimodal LLMs Perform Time Series Anomaly Detection?</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://xiongxiaoxu.github.io/">Xiongxiao Xu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://haoranwang18.github.io/">Haoran Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://yueqingliang1.github.io/">Yueqing Liang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en">Philip S. Yu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://viterbi-web.usc.edu/~yzhao010/">Yue Zhao</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.emory.edu/~kshu5/">Kai Shu</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Illinois Institute of Technology,</span>
            <span class="author-block"><sup>2</sup>Emory University,</span>
            <span class="author-block"><sup>3</sup>University of Illinois Chicago,</span>
            <span class="author-block"><sup>4</sup>University of Southern California</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2502.17812"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2502.17812"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mllm-ts/VisualTimeAnomaly"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code and Dataset</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png" alt="teaser" height="100%">
      <h2 class="subtitle has-text-centered">
        Left: workflow of VisualTimeAnomaly. Right: the performance comparison across various setting.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <!-- <div class="container is-max-desktop"> -->
    <!-- Image -->
    <!-- <br /> -->
<!--     <figure style="text-align: center;">
      <img src="static/images/teaser.png" alt="teaser">
    </figure> -->
  <!-- </div> -->
  <!-- <br> -->
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models (LLMs) have been increasingly used in time series analysis. However, the potential of multimodal LLMs (MLLMs), particularly vision-language models, for time series remains largely under-explored. 
            One natural way for humans to detect time series anomalies is through visualization and textual description. Motivated by this, we raise a critical and practical research question: Can multimodal LLMs perform time series anomaly detection?
          </p>
          <p>
            To answer this, we propose the VisualTimeAnomaly benchmark to evaluate MLLMs in time series anomaly detection (TSAD). Our approach transforms time series numerical data into the image format and feed these images into various MLLMs, including proprietary models (GPT-4o and Gemini-1.5) and open-source models (LLaVA-NeXT and Qwen2-VL), each with one larger and one smaller variant.
            In total, VisualTimeAnomaly contains 12.4k time series images spanning 3 scenarios and 3 anomaly granularities with 9 anomaly types across 8 MLLMs. Starting with the univariate case (point- and range-wise anomalies), we extend our evaluation to more practical scenarios, including multivariate and irregular time series scenarios, and variate-wise anomalies. Our study reveals several key insights: 
          </p>
          <p>
            <ul><p> 1) MLLMs detect range- and variate-wise anomalies more effectively than point-wise anomalies;  </p></ul>
            <ul><p> 2) MLLMs are highly robust to irregular time series, even with 25% of the data missing;  </p></ul>
            <ul><p> 3) open-source MLLMs perform comparably to proprietary models in TSAD. While open-source MLLMs excel on univariate time series, proprietary MLLMs demonstrate superior effectiveness on multivariate time series. </p></ul>
          </p>
          Finally, we discuss the broader implications of our findings for time series analysis in the era of MLLMs. We release our dataset and code at <a href="https://github.com/mllm-ts/VisualTimeAnomaly">HERE</a> to support future research.
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{xu2025can,
  title={Can Multimodal LLMs Perform Time Series Anomaly Detection?},
  author={Xu, Xiongxiao and Wang, Haoran and Liang, Yueqing and Yu, Philip S and Zhao, Yue and Shu, Kai},
  journal={arXiv preprint arXiv:2502.17812},
  year={2025}
}
</code></pre>
  </div>
</section>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" id="survey">Beyond Numbers: A Survey of Time Series Analysis in the Era of Multimodal LLMs</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://xiongxiaoxu.github.io/">Xiongxiao Xu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://viterbi-web.usc.edu/~yzhao010/">Yue Zhao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en">Philip S. Yu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.emory.edu/~kshu5/">Kai Shu</a><sup>4</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Illinois Institute of Technology,</span>
            <span class="author-block"><sup>2</sup>University of Southern California,</span>
            <span class="author-block"><sup>3</sup>University of Illinois Chicago,</span>
            <span class="author-block"><sup>4</sup>Emory University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="paper/MLLMTS_Survey.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.techrxiv.org/users/906388/articles/1281390-beyond-numbers-a-survey-of-time-series-analysis-in-the-era-of-multimodal-llms"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>TechRXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mllm-ts/Awesome-Multimodal-LLMs-Time-Series"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Paper List</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img src="./static/images/mllmts.png" alt="teaser" height="80%" width="80%">
      <h2 class="subtitle">
        Time series, traditionally represented as a temporally ordered sequence of numbers, can be flexibly expressed across diverse modalities, including text, images, graphs, audio, and tables
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <!-- <div class="container is-max-desktop"> -->
    <!-- Image -->
    <!-- <br /> -->
<!--     <figure style="text-align: center;">
      <img src="static/images/teaser.png" alt="teaser">
    </figure> -->
  <!-- </div> -->
  <!-- <br> -->
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          The rapid advancements in Multimodal Large Language Models (MLLMs) have garnered significant research attention, revolutionizing various domains, including time series analysis. Notably, time series data can be represented in diverse modalities, making it highly compatible with the progress of MLLMs. This survey provides a comprehensive overview of time series analysis in the era of multimodal LLMs. We systematically summarize existing work from two perspectives: data (taxonomy of time series modalities) and models (taxonomy of multimodal LLMs). From the data perspective, we emphasize that time series, traditionally represented as a sequence of numbers with temporal order, can also be expressed in modalities such as text, images, graphs, audio, and tables. From the model perspective, we explore MLLMs that are either applicable or hold potential for specific time series modalities. Finally, we identify future research directions and key challenges at the intersection of time series and MLLMs, including the video modality, reasoning, agents, interpretability, and hallucination. To support ongoing research, we maintain a GitHub repository to track the latest developments in this rapidly evolving field at <a href="https://github.com/mllm-ts/Awesome-Multimodal-LLMs-Time-Series">HERE</a>.
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{xu2025beyond,
  title={Beyond Numbers: A Survey of Time Series Analysis in the Era of Multimodal LLMs},
  author={Xu, Xiongxiao and Zhao, Yue and Yu, Philip S and Shu, Kai},
  url={https://mllm-ts.github.io/},
  year={2025}
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
